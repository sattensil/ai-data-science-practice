{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAPoU8Sm5E6e"
   },
   "source": [
    "# Feature Store: Streaming ingestion SDK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "24743cf4a1e1"
   },
   "source": [
    "**NOTE**: This notebook has been tested in the following environment:\n",
    "\n",
    "* Python version = 3.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvgnzT1CKxrO"
   },
   "source": [
    "## Overview\n",
    "\n",
    "This notebook demonstrates how to use Vertex AI Feature Store's streaming ingestion at the SDK layer.\n",
    "\n",
    "Learn more about [Vertex AI Feature Store](https://cloud.google.com/vertex-ai/docs/featurestore)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d975e698c9a4"
   },
   "source": [
    "### Objective\n",
    "\n",
    "In this tutorial, you learn how to ingest features from a `Pandas DataFrame` into your Vertex AI Feature Store using `write_feature_values` method from the Vertex AI SDK.\n",
    "\n",
    "This tutorial uses the following Google Cloud ML services and resources:\n",
    "\n",
    "- Vertex AI Feature Store\n",
    "\n",
    "\n",
    "The steps performed include:\n",
    "\n",
    "- Create `Feature Store`\n",
    "- Create new `Entity Type` for your `Feature Store`\n",
    "- Ingest feature values from `Pandas DataFrame` into `Feature Store`'s `Entity Types`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "08d289fa873f"
   },
   "source": [
    "### Dataset\n",
    "\n",
    "The dataset used for this notebook is the penguins dataset from [BigQuery public datasets](https://cloud.google.com/bigquery/public-data). This dataset has the following features: `culmen_length_mm`, `culmen_depth_mm`, `flipper_length_mm`, `body_mass_g`, `species`, and `sex`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aed92deeb4a0"
   },
   "source": [
    "### Costs\n",
    "\n",
    "This tutorial uses billable components of Google Cloud:\n",
    "\n",
    "* Vertex AI\n",
    "\n",
    "Learn about [Vertex AI\n",
    "pricing](https://cloud.google.com/vertex-ai/pricing) and use the [Pricing\n",
    "Calculator](https://cloud.google.com/products/calculator/)\n",
    "to generate a cost estimate based on your projected usage.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7EUnXsZhAGF"
   },
   "source": [
    "## Installation\n",
    "\n",
    "Install the following packages required to execute this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "2b4ef9b72d43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m  WARNING: The scripts f2py and numpy-config are installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script tb-gcp-uploader is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "apache-beam 2.46.0 requires grpcio!=1.48.0,<2,>=1.33.1, but you have grpcio 1.48.0 which is incompatible.\n",
      "apache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 2.1.3 which is incompatible.\n",
      "apache-beam 2.46.0 requires protobuf<4,>3.12.2, but you have protobuf 4.25.5 which is incompatible.\n",
      "apache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 18.0.0 which is incompatible.\n",
      "bigframes 0.22.0 requires pandas<2.1.4,>=1.5.0, but you have pandas 2.2.3 which is incompatible.\n",
      "dataproc-jupyter-plugin 0.1.80 requires aiohttp~=3.9.5, but you have aiohttp 3.10.5 which is incompatible.\n",
      "google-api-python-client 1.8.0 requires google-api-core<2dev,>=1.13.0, but you have google-api-core 2.23.0 which is incompatible.\n",
      "google-cloud-bigtable 1.7.3 requires protobuf<4.0.0dev, but you have protobuf 4.25.5 which is incompatible.\n",
      "google-cloud-datastore 1.15.5 requires protobuf<4.0.0dev, but you have protobuf 4.25.5 which is incompatible.\n",
      "google-cloud-language 1.3.2 requires protobuf<4.0.0dev, but you have protobuf 4.25.5 which is incompatible.\n",
      "google-cloud-pubsub 2.21.4 requires grpcio<2.0dev,>=1.51.3, but you have grpcio 1.48.0 which is incompatible.\n",
      "google-cloud-videointelligence 1.16.3 requires protobuf<4.0.0dev, but you have protobuf 4.25.5 which is incompatible.\n",
      "ibis-framework 7.1.0 requires numpy<2,>=1, but you have numpy 2.1.3 which is incompatible.\n",
      "ibis-framework 7.1.0 requires pyarrow<15,>=2, but you have pyarrow 18.0.0 which is incompatible.\n",
      "kfp 2.5.0 requires protobuf<4,>=3.13.0, but you have protobuf 4.25.5 which is incompatible.\n",
      "kfp-pipeline-spec 0.2.2 requires protobuf<4,>=3.13.0, but you have protobuf 4.25.5 which is incompatible.\n",
      "matplotlib 3.7.3 requires numpy<2,>=1.20, but you have numpy 2.1.3 which is incompatible.\n",
      "numba 0.58.1 requires numpy<1.27,>=1.22, but you have numpy 2.1.3 which is incompatible.\n",
      "scipy 1.11.4 requires numpy<1.28.0,>=1.21.6, but you have numpy 2.1.3 which is incompatible.\n",
      "tensorboard 2.11.2 requires protobuf<4,>=3.9.2, but you have protobuf 4.25.5 which is incompatible.\n",
      "tensorboardx 2.6 requires protobuf<4,>=3.8.0, but you have protobuf 4.25.5 which is incompatible.\n",
      "tensorflow 2.11.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.25.5 which is incompatible.\n",
      "tensorflow-metadata 0.14.0 requires protobuf<4,>=3.7, but you have protobuf 4.25.5 which is incompatible.\n",
      "tensorflow-serving-api 2.11.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.25.5 which is incompatible.\n",
      "tensorflow-transform 0.14.0 requires numpy<2,>=1.16, but you have numpy 2.1.3 which is incompatible.\n",
      "tensorflow-transform 0.14.0 requires protobuf<4,>=3.7, but you have protobuf 4.25.5 which is incompatible.\n",
      "ydata-profiling 4.6.0 requires numpy<1.26,>=1.16.0, but you have numpy 2.1.3 which is incompatible.\n",
      "ydata-profiling 4.6.0 requires pandas!=1.4.0,<2.1,>1.1, but you have pandas 2.2.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Install the packages\n",
    "! pip3 install --upgrade google-cloud-aiplatform\\\n",
    "                         google-cloud-bigquery\\\n",
    "                         numpy\\\n",
    "                         pandas\\\n",
    "                         db-dtypes\\\n",
    "                         pyarrow -q\\\n",
    "                         --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** You can ignore the dependency and incompatibility errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "58707a750154"
   },
   "source": [
    "### Restart the kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "f200f10a1da3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Automatically restart kernel after installs so that your environment can access the new packages\n",
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BF1j6f9HApxa"
   },
   "source": [
    "## Before you begin\n",
    "\n",
    "### Set up your Google Cloud project\n",
    "\n",
    "**The following steps are required, regardless of your notebook environment.**\n",
    "\n",
    "1. [Select or create a Google Cloud project](https://console.cloud.google.com/cloud-resource-manager). When you first create an account, you get a $300 free credit towards your compute/storage costs.\n",
    "\n",
    "2. [Make sure that billing is enabled for your project](https://cloud.google.com/billing/docs/how-to/modify-project).\n",
    "\n",
    "3. [Enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
    "\n",
    "4. If you are running this notebook locally, you need to install the [Cloud SDK](https://cloud.google.com/sdk)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WReHDGG5g0XY"
   },
   "source": [
    "#### Set your project ID\n",
    "\n",
    "**If you don't know your project ID**, try the following:\n",
    "* Run `gcloud config list`.\n",
    "* Run `gcloud projects list`.\n",
    "* See the support page: [Locate the project ID](https://support.google.com/googleapi/answer/7014113)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "oM1iC_MfAts1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ID = \"qwiklabs-gcp-04-1cf1ee4bd6dc\"  # Replace with your project-id\n",
    "\n",
    "# Set the project id\n",
    "! gcloud config set project {PROJECT_ID}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "region"
   },
   "source": [
    "#### Region\n",
    "\n",
    "You can also change the `REGION` variable used by Vertex AI. Learn more about [Vertex AI regions](https://cloud.google.com/vertex-ai/docs/general/locations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "kljmKgilI_de"
   },
   "outputs": [],
   "source": [
    "REGION = \"us-east1\"  # Replace with your region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EsCYkJ4IU-z4"
   },
   "source": [
    "### UUID\n",
    "\n",
    "If you are in a live tutorial session, you might be using a shared test account or project. To avoid name collisions between users on resources created, you create a uuid for each instance session, and append it onto the name of resources you create in this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "4jWj2DSTU9my"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "\n",
    "\n",
    "# Generate a uuid of a specifed length(default=8)\n",
    "def generate_uuid(length: int = 8) -> str:\n",
    "    return \"\".join(random.choices(string.ascii_lowercase + string.digits, k=length))\n",
    "\n",
    "\n",
    "UUID = generate_uuid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "960505627ddf"
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "PyQmSRbKA8r-"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from google.cloud import aiplatform, bigquery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "init_aip:mbsdk,all"
   },
   "source": [
    "### Initialize Vertex AI SDK for Python\n",
    "\n",
    "Initialize the Vertex AI SDK for Python for your project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "0ep8KuQhI_df"
   },
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=REGION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k5XsEiAuEWUJ"
   },
   "source": [
    "## Download and prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "rOd7Ixa1pqBY"
   },
   "outputs": [],
   "source": [
    "def download_bq_table(bq_table_uri: str) -> pd.DataFrame:\n",
    "    # Remove bq:// prefix if present\n",
    "    prefix = \"bq://\"\n",
    "    if bq_table_uri.startswith(prefix):\n",
    "        bq_table_uri = bq_table_uri[len(prefix) :]\n",
    "\n",
    "    table = bigquery.TableReference.from_string(bq_table_uri)\n",
    "\n",
    "    # Create a BigQuery client\n",
    "    bqclient = bigquery.Client(project=PROJECT_ID)\n",
    "\n",
    "    # Download the table rows\n",
    "    rows = bqclient.list_rows(\n",
    "        table,\n",
    "    )\n",
    "    return rows.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "SdX_m1Uppkfu"
   },
   "outputs": [],
   "source": [
    "BQ_SOURCE = \"bq://bigquery-public-data.ml_datasets.penguins\"\n",
    "\n",
    "# Download penguins BigQuery table\n",
    "penguins_df = download_bq_table(BQ_SOURCE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QuQe6mSbFbhm"
   },
   "source": [
    "### Prepare the data\n",
    "\n",
    "Feature values to be written to the Feature Store can take the form of a list of `WriteFeatureValuesPayload` objects, a Python `dict` of the form\n",
    "\n",
    "`{entity_id : {feature_id : feature_value}, ...},`\n",
    "\n",
    "or a pandas `Dataframe`, where the `index` column holds the unique entity ID strings and each remaining column represents a feature.  In this notebook, since you use a pandas `DataFrame` for ingesting features we convert the index column data type to `string` to be used as `Entity ID`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "cljxzJ3bqDer"
   },
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "penguins_df.index = penguins_df.index.map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "GSxrSdSY2ovn"
   },
   "outputs": [],
   "source": [
    "# Remove null values\n",
    "NA_VALUES = [\"NA\", \".\"]\n",
    "penguins_df = penguins_df.replace(to_replace=NA_VALUES, value=np.nan).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vgn4oQmSqdKI"
   },
   "source": [
    "## Create Feature Store and define schemas\n",
    "\n",
    "Vertex AI Feature Store organizes resources hierarchically in the following order:\n",
    "\n",
    "`Featurestore -> EntityType -> Feature`\n",
    "\n",
    "You must create these resources before you can ingest data into Vertex AI Feature Store.\n",
    "\n",
    "Learn more about [Vertex AI Feature Store](https://cloud.google.com/vertex-ai/docs/featurestore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yaHwdbGjZWTq"
   },
   "source": [
    "### Create a Feature Store\n",
    "\n",
    "You create a Feature Store using `aiplatform.Featurestore.create` with the following parameters:\n",
    "\n",
    "* `featurestore_id (str)`: The ID to use for this Featurestore, which will become the final component of the Featurestore's resource name. The value must be unique within the project and location.\n",
    "* `online_store_fixed_node_count`: Configuration for online serving resources.\n",
    "* `project`: Project to create EntityType in. If not set, project set in `aiplatform.init` is used.\n",
    "* `location`: Location to create EntityType in. If not set, location set in `aiplatform.init` is used.\n",
    "* `sync`:  Whether to execute this creation synchronously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "cImsONglqfxO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Featurestore\n",
      "Create Featurestore backing LRO: projects/1099254572636/locations/us-east1/featurestores/penguins_xecovnzl/operations/5334605155524411392\n",
      "Featurestore created. Resource name: projects/1099254572636/locations/us-east1/featurestores/penguins_xecovnzl\n",
      "To use this Featurestore in another session:\n",
      "featurestore = aiplatform.Featurestore('projects/1099254572636/locations/us-east1/featurestores/penguins_xecovnzl')\n"
     ]
    }
   ],
   "source": [
    "FEATURESTORE_ID = f\"penguins_{UUID}\"\n",
    "\n",
    "penguins_feature_store = aiplatform.Featurestore.create(\n",
    "    featurestore_id=FEATURESTORE_ID,\n",
    "    online_store_fixed_node_count=1,\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    "    sync=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UfXgSD1VdzKb"
   },
   "source": [
    "##### Verify that the Feature Store is created\n",
    "Check if the Feature Store was successfully created by running the following code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "oud1OdfQd52r"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"projects/1099254572636/locations/us-east1/featurestores/penguins_xecovnzl\"\n",
      "create_time {\n",
      "  seconds: 1731383746\n",
      "  nanos: 467745000\n",
      "}\n",
      "update_time {\n",
      "  seconds: 1731383746\n",
      "  nanos: 558278000\n",
      "}\n",
      "etag: \"AMEw9yPIly5y_ZoXqk6hRRsr4LYOrrrlIT3lvusrH-GJ9g_U_IWty1hGI_VABaGG5LNo\"\n",
      "online_serving_config {\n",
      "  fixed_node_count: 1\n",
      "}\n",
      "state: STABLE\n",
      "online_storage_ttl_days: 4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fs = aiplatform.Featurestore(\n",
    "    featurestore_name=FEATURESTORE_ID,\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    ")\n",
    "print(fs.gca_resource)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ep74rSlJWF3c"
   },
   "source": [
    "### Create an EntityType\n",
    "\n",
    "An entity type is a collection of semantically related features. You define your own entity types, based on the concepts that are relevant to your use case. For example, a movie service might have the entity types `movie` and `user`, which group related features that correspond to movies or users.\n",
    "\n",
    "Here, you create an entity type entity type named `penguin_entity_type` using `create_entity_type` with the following parameters:\n",
    "* `entity_type_id (str)`: The ID to use for the EntityType, which will become the final component of the EntityType's resource name. The value must be unique within a Feature Store.\n",
    "* `description`: Description of the EntityType."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "zNzr-FlEr3tI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating EntityType\n",
      "Create EntityType backing LRO: projects/1099254572636/locations/us-east1/featurestores/penguins_xecovnzl/entityTypes/penguin_entity_type_xecovnzl/operations/1083207107286663168\n",
      "EntityType created. Resource name: projects/1099254572636/locations/us-east1/featurestores/penguins_xecovnzl/entityTypes/penguin_entity_type_xecovnzl\n",
      "To use this EntityType in another session:\n",
      "entity_type = aiplatform.EntityType('projects/1099254572636/locations/us-east1/featurestores/penguins_xecovnzl/entityTypes/penguin_entity_type_xecovnzl')\n"
     ]
    }
   ],
   "source": [
    "ENTITY_TYPE_ID = f\"penguin_entity_type_{UUID}\"\n",
    "\n",
    "# Create penguin entity type\n",
    "penguins_entity_type = penguins_feature_store.create_entity_type(\n",
    "    entity_type_id=ENTITY_TYPE_ID,\n",
    "    description=\"Penguins entity type\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CquSdTp7duVw"
   },
   "source": [
    "##### Verify that the EntityType is created\n",
    "Check if the Entity Type was successfully created by running the following code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "76ocr_hJsG-t"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"projects/1099254572636/locations/us-east1/featurestores/penguins_xecovnzl/entityTypes/penguin_entity_type_xecovnzl\"\n",
      "description: \"Penguins entity type\"\n",
      "create_time {\n",
      "  seconds: 1731383751\n",
      "  nanos: 12149000\n",
      "}\n",
      "update_time {\n",
      "  seconds: 1731383751\n",
      "  nanos: 12149000\n",
      "}\n",
      "etag: \"AMEw9yMZdX8bWITjom3HiaT0B43q2evpGddanuaklrz0bjOUCcgewKUGdch51k1qm4M=\"\n",
      "monitoring_config {\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "entity_type = penguins_feature_store.get_entity_type(entity_type_id=ENTITY_TYPE_ID)\n",
    "\n",
    "print(entity_type.gca_resource)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2vYV2UUFehwZ"
   },
   "source": [
    "### Create Features\n",
    "A feature is a measurable property or attribute of an entity type. For example, `penguin` entity type has features such as `flipper_length_mm`, and `body_mass_g`. Features can be created within each entity type.\n",
    "\n",
    "When you create a feature, you specify its value type such as `DOUBLE`, and `STRING`. This value determines what value types you can ingest for a particular feature.\n",
    "\n",
    "Learn more about [Feature Value Types](https://cloud.google.com/vertex-ai/docs/reference/rest/v1/projects.locations.featurestores.entityTypes.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "WQ5EsPPbsSuE"
   },
   "outputs": [],
   "source": [
    "penguins_feature_configs = {\n",
    "    \"species\": {\n",
    "        \"value_type\": \"STRING\",\n",
    "    },\n",
    "    \"island\": {\n",
    "        \"value_type\": \"STRING\",\n",
    "    },\n",
    "    \"culmen_length_mm\": {\n",
    "        \"value_type\": \"DOUBLE\",\n",
    "    },\n",
    "    \"culmen_depth_mm\": {\n",
    "        \"value_type\": \"DOUBLE\",\n",
    "    },\n",
    "    \"flipper_length_mm\": {\n",
    "        \"value_type\": \"DOUBLE\",\n",
    "    },\n",
    "    \"body_mass_g\": {\"value_type\": \"DOUBLE\"},\n",
    "    \"sex\": {\"value_type\": \"STRING\"},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AKRXJCPijM8w"
   },
   "source": [
    "You can create features either using `create_feature` or `batch_create_features`. Here, for convinience, you have added all feature configs in one variabel, so we use `batch_create_features`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "tXOI1Onhs46x"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch creating features EntityType entityType: projects/1099254572636/locations/us-east1/featurestores/penguins_xecovnzl/entityTypes/penguin_entity_type_xecovnzl\n",
      "Batch create Features EntityType entityType backing LRO: projects/1099254572636/locations/us-east1/featurestores/penguins_xecovnzl/entityTypes/penguin_entity_type_xecovnzl/operations/1803783047665942528\n",
      "EntityType entityType Batch created features. Resource name: projects/1099254572636/locations/us-east1/featurestores/penguins_xecovnzl/entityTypes/penguin_entity_type_xecovnzl\n"
     ]
    }
   ],
   "source": [
    "penguin_features = penguins_entity_type.batch_create_features(\n",
    "    feature_configs=penguins_feature_configs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WBx26pZItUN4"
   },
   "source": [
    "### Write features to the Feature Store\n",
    "Use the `write_feature_values` API to write a feature to the Feature Store with the following parameter:\n",
    "\n",
    "* `instances`: Feature values to be written to the Feature Store that can take the form of a list of WriteFeatureValuesPayload objects, a Python dict, or a pandas Dataframe.\n",
    "\n",
    "This streaming ingestion feature has been introduced to the Vertex AI SDK under the **preview** namespace. Here, you pass the pandas `Dataframe` you created from penguins dataset as `instances` parameter.\n",
    "\n",
    "Learn more about [Streaming ingestion API](https://github.com/googleapis/python-aiplatform/blob/e6933503d2d3a0f8a8f7ef8c178ed50a69ac2268/google/cloud/aiplatform/preview/featurestore/entity_type.py#L36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "iUGI-ftltXqE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing EntityType feature values: projects/1099254572636/locations/us-east1/featurestores/penguins_xecovnzl/entityTypes/penguin_entity_type_xecovnzl\n",
      "EntityType feature values written. Resource name: projects/1099254572636/locations/us-east1/featurestores/penguins_xecovnzl/entityTypes/penguin_entity_type_xecovnzl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<google.cloud.aiplatform.preview.featurestore.entity_type.EntityType object at 0x7fa02a203310> \n",
       "resource name: projects/1099254572636/locations/us-east1/featurestores/penguins_xecovnzl/entityTypes/penguin_entity_type_xecovnzl"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penguins_entity_type.preview.write_feature_values(instances=penguins_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "STq67KHO3q_e"
   },
   "source": [
    "## Read back written features\n",
    "\n",
    "Wait a few seconds for the write to propagate, then do an online read to confirm the write was successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lwoMnze43r9G"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity_id</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>culmen_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>culmen_length_mm</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3475.0</td>\n",
       "      <td>Adelie Penguin (Pygoscelis adeliae)</td>\n",
       "      <td>Dream</td>\n",
       "      <td>18.4</td>\n",
       "      <td>184.0</td>\n",
       "      <td>36.6</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4650.0</td>\n",
       "      <td>Adelie Penguin (Pygoscelis adeliae)</td>\n",
       "      <td>Dream</td>\n",
       "      <td>19.1</td>\n",
       "      <td>184.0</td>\n",
       "      <td>39.8</td>\n",
       "      <td>MALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>4300.0</td>\n",
       "      <td>Adelie Penguin (Pygoscelis adeliae)</td>\n",
       "      <td>Dream</td>\n",
       "      <td>18.9</td>\n",
       "      <td>208.0</td>\n",
       "      <td>40.8</td>\n",
       "      <td>MALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>3650.0</td>\n",
       "      <td>Adelie Penguin (Pygoscelis adeliae)</td>\n",
       "      <td>Dream</td>\n",
       "      <td>18.7</td>\n",
       "      <td>185.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>MALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>Adelie Penguin (Pygoscelis adeliae)</td>\n",
       "      <td>Dream</td>\n",
       "      <td>16.9</td>\n",
       "      <td>185.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>3150.0</td>\n",
       "      <td>Adelie Penguin (Pygoscelis adeliae)</td>\n",
       "      <td>Dream</td>\n",
       "      <td>18.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>36.5</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>3425.0</td>\n",
       "      <td>Adelie Penguin (Pygoscelis adeliae)</td>\n",
       "      <td>Dream</td>\n",
       "      <td>19.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>41.1</td>\n",
       "      <td>MALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>Adelie Penguin (Pygoscelis adeliae)</td>\n",
       "      <td>Dream</td>\n",
       "      <td>17.9</td>\n",
       "      <td>190.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>3900.0</td>\n",
       "      <td>Adelie Penguin (Pygoscelis adeliae)</td>\n",
       "      <td>Dream</td>\n",
       "      <td>17.5</td>\n",
       "      <td>190.0</td>\n",
       "      <td>41.1</td>\n",
       "      <td>MALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>Adelie Penguin (Pygoscelis adeliae)</td>\n",
       "      <td>Dream</td>\n",
       "      <td>19.5</td>\n",
       "      <td>190.0</td>\n",
       "      <td>36.3</td>\n",
       "      <td>MALE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   entity_id  body_mass_g                              species island  \\\n",
       "0          0       3475.0  Adelie Penguin (Pygoscelis adeliae)  Dream   \n",
       "1          1       4650.0  Adelie Penguin (Pygoscelis adeliae)  Dream   \n",
       "2         10       4300.0  Adelie Penguin (Pygoscelis adeliae)  Dream   \n",
       "3         11       3650.0  Adelie Penguin (Pygoscelis adeliae)  Dream   \n",
       "4         12       3000.0  Adelie Penguin (Pygoscelis adeliae)  Dream   \n",
       "..       ...          ...                                  ...    ...   \n",
       "95        95       3150.0  Adelie Penguin (Pygoscelis adeliae)  Dream   \n",
       "96        96       3425.0  Adelie Penguin (Pygoscelis adeliae)  Dream   \n",
       "97        97       3450.0  Adelie Penguin (Pygoscelis adeliae)  Dream   \n",
       "98        98       3900.0  Adelie Penguin (Pygoscelis adeliae)  Dream   \n",
       "99        99       3800.0  Adelie Penguin (Pygoscelis adeliae)  Dream   \n",
       "\n",
       "    culmen_depth_mm  flipper_length_mm  culmen_length_mm     sex  \n",
       "0              18.4              184.0              36.6  FEMALE  \n",
       "1              19.1              184.0              39.8    MALE  \n",
       "2              18.9              208.0              40.8    MALE  \n",
       "3              18.7              185.0              39.0    MALE  \n",
       "4              16.9              185.0              37.0  FEMALE  \n",
       "..              ...                ...               ...     ...  \n",
       "95             18.0              182.0              36.5  FEMALE  \n",
       "96             19.0              182.0              41.1    MALE  \n",
       "97             17.9              190.0              36.0  FEMALE  \n",
       "98             17.5              190.0              41.1    MALE  \n",
       "99             19.5              190.0              36.3    MALE  \n",
       "\n",
       "[100 rows x 8 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ENTITY_IDS = [str(x) for x in range(100)]\n",
    "penguins_entity_type.read(entity_ids=ENTITY_IDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The newly created feature store will be only be visible in the Console when \"Vertex AI Feature Store (Legacy)\" is selected from the top right menu. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TpV-iwP9qw9c"
   },
   "source": [
    "## Cleaning up\n",
    "\n",
    "To clean up all Google Cloud resources used in this project, you can [delete the Google Cloud\n",
    "project](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects) you used for the tutorial.\n",
    "\n",
    "Otherwise, you can delete the individual resources you created in this tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sx_vKniMq9ZX",
    "tags": []
   },
   "outputs": [],
   "source": [
    "penguins_feature_store.delete(force=True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "feature_store_streaming_ingestion_sdk.ipynb",
   "toc_visible": true
  },
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m125"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
